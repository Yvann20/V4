import json
import subprocess
import os
import sys
import time
import threading
import logging
from datetime import timedelta
from typing import Dict, Any, Optional
from pathlib import Path
import redis
from rq import Queue
from rq.job import Job
from rq.exceptions import NoSuchJobError
import shared

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('tasks.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Configura√ß√µes Redis com pool otimizado
REDIS_HOST = os.environ.get("REDIS_HOST", "localhost")
REDIS_PORT = int(os.environ.get("REDIS_PORT", 6379))
REDIS_DB = int(os.environ.get("REDIS_DB", 0))
REDIS_MAX_CONNECTIONS = int(os.environ.get("REDIS_MAX_CONNECTIONS", 50))
REDIS_SOCKET_TIMEOUT = int(os.environ.get("REDIS_SOCKET_TIMEOUT", 10))
REDIS_SOCKET_CONNECT_TIMEOUT = int(os.environ.get("REDIS_SOCKET_CONNECT_TIMEOUT", 5))

# Configura√ß√µes de performance
JOB_TIMEOUT = int(os.environ.get("JOB_TIMEOUT", 300))  # 5 minutos
JOB_RESULT_TTL = int(os.environ.get("JOB_RESULT_TTL", 3600))  # 1 hora
FAILED_JOB_TTL = int(os.environ.get("FAILED_JOB_TTL", 86400))  # 24 horas
MAX_RETRIES = int(os.environ.get("MAX_TASK_RETRIES", 3))
RETRY_DELAYS = [60, 300, 900]  # 1min, 5min, 15min

# Pool de conex√µes Redis com configura√ß√µes otimizadas
redis_pool = redis.ConnectionPool(
    host=REDIS_HOST,
    port=REDIS_PORT,
    db=REDIS_DB,
    max_connections=REDIS_MAX_CONNECTIONS,
    socket_timeout=REDIS_SOCKET_TIMEOUT,
    socket_connect_timeout=REDIS_SOCKET_CONNECT_TIMEOUT,
    retry_on_timeout=True,
    health_check_interval=30,
    socket_keepalive=True,
    socket_keepalive_options={}
)

# Cliente Redis configurado
redis_client = redis.StrictRedis(
    connection_pool=redis_pool,
    decode_responses=False
)

# Configurar fila RQ com configura√ß√µes otimizadas
if not hasattr(shared, 'rq_queue') or shared.rq_queue is None:
    shared.rq_queue = Queue(
        "bot_tasks",
        connection=redis_client,
        default_timeout=JOB_TIMEOUT,
        result_ttl=JOB_RESULT_TTL,
        failure_ttl=FAILED_JOB_TTL
    )

# Filas adicionais para prioridade
high_priority_queue = Queue("high_priority", connection=redis_client, default_timeout=JOB_TIMEOUT)
low_priority_queue = Queue("low_priority", connection=redis_client, default_timeout=JOB_TIMEOUT)

# Lock para opera√ß√µes thread-safe
_lock = threading.Lock()

# Garantir que vari√°veis compartilhadas estejam definidas
if not hasattr(shared, 'active_campaigns'):
    shared.active_campaigns = {}
if not hasattr(shared, 'user_clients'):
    shared.user_clients = {}
if not hasattr(shared, 'user_settings'):
    shared.user_settings = {}
if not hasattr(shared, 'user_group_list'):
    shared.user_group_list = {}
if not hasattr(shared, 'statistics'):
    shared.statistics = {"messages_sent": 0, "active_campaigns": 0}

# Cache para msgpack com fallback para JSON
try:
    import msgpack
    HAS_MSGPACK = True
    logger.info("msgpack dispon√≠vel - usando serializa√ß√£o bin√°ria otimizada")
except ImportError:
    msgpack = None
    HAS_MSGPACK = False
    logger.warning("msgpack n√£o encontrado - usando JSON como fallback")

def get_redis_connection() -> redis.StrictRedis:
    """Obt√©m conex√£o Redis com retry autom√°tico"""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # Testar conex√£o
            redis_client.ping()
            return redis_client
        except redis.ConnectionError as e:
            if attempt == max_retries - 1:
                logger.error(f"Falha ao conectar Redis ap√≥s {max_retries} tentativas: {e}")
                raise
            logger.warning(f"Erro de conex√£o Redis (tentativa {attempt + 1}): {e}")
            time.sleep(2 ** attempt)  # Backoff exponencial

def serialize_data(data: Dict[str, Any]) -> bytes:
    """Serializa dados usando msgpack ou JSON"""
    try:
        if HAS_MSGPACK:
            return msgpack.packb(data, use_bin_type=True)
        else:
            import json
            return json.dumps(data).encode('utf-8')
    except Exception as e:
        logger.error(f"Erro ao serializar dados: {e}")
        # Fallback para JSON simples
        import json
        return json.dumps(str(data)).encode('utf-8')

def deserialize_data(data: bytes) -> Dict[str, Any]:
    """Deserializa dados usando msgpack ou JSON"""
    try:
        if HAS_MSGPACK:
            return msgpack.unpackb(data, raw=False)
        else:
            import json
            return json.loads(data.decode('utf-8'))
    except Exception as e:
        logger.error(f"Erro ao deserializar dados: {e}")
        return {}

def load_cache(user_id: int) -> Dict[str, Any]:
    """Carrega cache do usu√°rio com tratamento de erro melhorado"""
    key = f"usercache:{user_id}"
    try:
        redis_conn = get_redis_connection()
        packed = redis_conn.get(key)
        if packed is not None:
            return deserialize_data(packed)
        logger.debug(f"Cache n√£o encontrado para usu√°rio {user_id}")
        return {}
    except Exception as e:
        logger.error(f"Erro ao carregar cache para user_id {user_id}: {str(e)}")
        return {}

def save_cache(user_id: int, data: Dict[str, Any], ttl: int = 3600) -> bool:
    """Salva cache com TTL configur√°vel e retry"""
    key = f"usercache:{user_id}"
    try:
        redis_conn = get_redis_connection()
        packed = serialize_data(data)
        redis_conn.setex(key, ttl, packed)
        logger.debug(f"Cache salvo para usu√°rio {user_id} com TTL {ttl}s")
        return True
    except Exception as e:
        logger.error(f"Erro ao salvar cache para user_id {user_id}: {str(e)}")
        return False

def delete_cache(user_id: int) -> bool:
    """Remove cache do usu√°rio"""
    key = f"usercache:{user_id}"
    try:
        redis_conn = get_redis_connection()
        redis_conn.delete(key)
        logger.debug(f"Cache removido para usu√°rio {user_id}")
        return True
    except Exception as e:
        logger.error(f"Erro ao remover cache para user_id {user_id}: {str(e)}")
        return False

def execute_async_helper(user_id: int, link: str, timeout: int = JOB_TIMEOUT) -> Dict[str, Any]:
    """Executa o script async_helper.py com timeout e tratamento de erro robusto"""
    try:
        # Verificar se arquivo exists
        script_path = Path("async_helper.py")
        if not script_path.exists():
            logger.error("async_helper.py n√£o encontrado")
            return {"status": "error", "message": "Script auxiliar n√£o encontrado"}

        # Preparar comando
        cmd = [sys.executable, str(script_path), str(user_id), link]

        logger.info(f"Executando script auxiliar para usu√°rio {user_id} com link {link}")

        # Executar com timeout
        process = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=timeout,
            check=False,
            cwd=os.getcwd(),
            env=os.environ.copy()
        )

        # Verificar se processo executou com sucesso
        if process.returncode != 0:
            error_msg = process.stderr.strip() if process.stderr else "Erro desconhecido"
            logger.error(f"Script auxiliar falhou para usu√°rio {user_id}: {error_msg}")
            return {
                "status": "error",
                "message": f"Falha na execu√ß√£o: {error_msg}",
                "return_code": process.returncode
            }

        # Parse da sa√≠da
        output = process.stdout.strip()
        if not output:
            logger.warning(f"Script auxiliar retornou sa√≠da vazia para usu√°rio {user_id}")
            return {"status": "error", "message": "Sa√≠da vazia do script auxiliar"}

        try:
            result = json.loads(output)
            logger.info(f"Script auxiliar executado com sucesso para usu√°rio {user_id}")
            return result
        except json.JSONDecodeError as e:
            logger.error(f"Erro ao decodificar JSON do script auxiliar para usu√°rio {user_id}: {e}")
            logger.debug(f"Sa√≠da bruta: {output}")
            return {
                "status": "error",
                "message": "Resposta inv√°lida do script auxiliar",
                "raw_output": output
            }
    except subprocess.TimeoutExpired:
        logger.error(f"Timeout ({timeout}s) ao executar script auxiliar para usu√°rio {user_id}")
        shared.update_user_statistics(user_id, 'failed_forwards')
        return {"status": "error", "message": f"Timeout ap√≥s {timeout} segundos"}
    except FileNotFoundError:
        logger.error("Python interpreter n√£o encontrado")
        return {"status": "error", "message": "Interpretador Python n√£o encontrado"}
    except Exception as e:
        logger.error(f"Erro inesperado ao executar script auxiliar para usu√°rio {user_id}: {str(e)}")
        shared.update_user_statistics(user_id, 'failed_forwards')
        return {"status": "error", "message": f"Erro inesperado: {str(e)}"}

def should_retry_task(result: Dict[str, Any], attempt: int) -> bool:
    """Determina se uma tarefa deve ser reexecutada"""
    if attempt >= MAX_RETRIES:
        return False

    # Sempre retry para erros de timeout ou conex√£o
    error_msg = result.get("message", "").lower()
    retry_conditions = [
        "timeout" in error_msg,
        "connection" in error_msg,
        "flood" in error_msg,
        "network" in error_msg,
        "temporary" in error_msg
    ]
    return any(retry_conditions)

def forward_message_com_RQ(user_id: int, attempt: int = 1) -> Dict[str, Any]:
    """Fun√ß√£o principal para encaminhamento com otimiza√ß√µes e retry autom√°tico"""
    try:
        # Verificar rate limiting
        if shared.is_rate_limited(user_id):
            logger.warning(f"Rate limit atingido para usu√°rio {user_id}")
            return {"status": "error", "message": "Rate limit atingido"}

        # Carregar dados do cache
        cache_data = load_cache(user_id)
        link = cache_data.get("msg_link")

        if not link:
            logger.warning(f"Link de mensagem n√£o encontrado no cache para usu√°rio {user_id}")
            return {"status": "error", "message": "Link de mensagem n√£o encontrado"}

        logger.info(f"Iniciando encaminhamento para usu√°rio {user_id} (tentativa {attempt}) com link {link}")

        # Executar script auxiliar
        result = execute_async_helper(user_id, link)

        # Atualizar estat√≠sticas baseado no resultado
        if result.get("status") == "success":
            shared.update_user_statistics(user_id, 'successful_forwards')
            logger.info(f"Encaminhamento bem-sucedido para usu√°rio {user_id}")
        else:
            shared.update_user_statistics(user_id, 'failed_forwards')
            logger.warning(f"Encaminhamento falhou para usu√°rio {user_id}: {result.get('message')}")

        # Verificar se deve fazer retry
        if should_retry_task(result, attempt):
            delay = RETRY_DELAYS[min(attempt - 1, len(RETRY_DELAYS) - 1)]
            logger.info(f"Agendando retry {attempt + 1} para usu√°rio {user_id} em {delay}s")
            # Agendar retry
            shared.rq_queue.enqueue_in(
                timedelta(seconds=delay),
                forward_message_com_RQ,
                user_id,
                attempt + 1,
                job_timeout=JOB_TIMEOUT,
                result_ttl=JOB_RESULT_TTL
            )

        # Reenfileirar pr√≥xima execu√ß√£o se campanha ainda ativa
        interval = cache_data.get("interval")
        if interval and user_id in shared.active_campaigns:
            schedule_next_execution(user_id, interval)
        else:
            logger.info(f"Campanha n√£o est√° mais ativa para usu√°rio {user_id}")

        return result

    except Exception as e:
        logger.error(f"Erro geral na fun√ß√£o forward_message_com_RQ para usu√°rio {user_id}: {str(e)}", exc_info=True)
        shared.update_user_statistics(user_id, 'failed_forwards')
        return {"status": "error", "message": f"Erro interno: {str(e)}"}

def schedule_next_execution(user_id: int, interval: int) -> Optional[Job]:
    """Agenda pr√≥xima execu√ß√£o da tarefa"""
    try:
        interval_minutes = int(interval)
        # Adicionar jitter para distribuir carga
        import random
        jitter_seconds = random.randint(0, min(30, interval_minutes * 6))  # At√© 10% do intervalo ou 30s
        delay = timedelta(minutes=interval_minutes, seconds=jitter_seconds)
        # Enfileirar pr√≥xima tarefa
        job = shared.rq_queue.enqueue_in(
            delay,
            forward_message_com_RQ,
            user_id,
            1,  # Reset attempt counter
            job_timeout=JOB_TIMEOUT,
            result_ttl=JOB_RESULT_TTL
        )
        if job:
            # Atualizar job_id na campanha ativa
            with _lock:
                if user_id in shared.active_campaigns:
                    shared.active_campaigns[user_id]['job_id'] = job.id
            logger.info(f"Pr√≥xima execu√ß√£o agendada para usu√°rio {user_id} em {delay.total_seconds():.0f}s")
            return job
        else:
            logger.error(f"Falha ao agendar pr√≥xima execu√ß√£o para usu√°rio {user_id}")
    except Exception as e:
        logger.error(f"Erro ao agendar pr√≥xima execu√ß√£o para usu√°rio {user_id}: {str(e)}")
    return None

def cleanup_expired_jobs() -> Dict[str, int]:
    """Remove jobs expirados das filas"""
    try:
        cleaned = {"failed": 0, "finished": 0, "scheduled": 0}
        # Limpar jobs falhados antigos (mais de 24h)
        failed_registry = shared.rq_queue.failed_job_registry
        before_failed = len(failed_registry)
        failed_registry.cleanup(timestamp=time.time() - FAILED_JOB_TTL)
        cleaned["failed"] = before_failed - len(failed_registry)
        # Limpar jobs finalizados antigos (mais de 1h)
        finished_registry = shared.rq_queue.finished_job_registry
        before_finished = len(finished_registry)
        finished_registry.cleanup(timestamp=time.time() - JOB_RESULT_TTL)
        cleaned["finished"] = before_finished - len(finished_registry)
        # Limpar jobs agendados √≥rf√£os
        scheduled_registry = shared.rq_queue.scheduled_job_registry
        before_scheduled = len(scheduled_registry)
        # Remover jobs de usu√°rios que n√£o t√™m mais campanha ativa
        orphaned_jobs = []
        for job_id in scheduled_registry.get_job_ids():
            try:
                job = Job.fetch(job_id, connection=redis_client)
                if job.args and len(job.args) > 0:
                    job_user_id = job.args[0]
                    if job_user_id not in shared.active_campaigns:
                        orphaned_jobs.append(job_id)
            except (NoSuchJobError, AttributeError, IndexError):
                orphaned_jobs.append(job_id)
        for job_id in orphaned_jobs:
            try:
                scheduled_registry.remove(job_id)
            except Exception:
                pass
        cleaned["scheduled"] = len(orphaned_jobs)
        if any(cleaned.values()):
            logger.info(f"Limpeza conclu√≠da: {cleaned}")
        return cleaned
    except Exception as e:
        logger.error(f"Erro na limpeza de jobs: {e}")
        return {"failed": 0, "finished": 0, "scheduled": 0}

def get_queue_statistics() -> Dict[str, Any]:
    """Retorna estat√≠sticas detalhadas das filas"""
    try:
        return {
            "main_queue": {
                "pending": len(shared.rq_queue),
                "failed": len(shared.rq_queue.failed_job_registry),
                "finished": len(shared.rq_queue.finished_job_registry),
                "scheduled": len(shared.rq_queue.scheduled_job_registry),
                "started": len(shared.rq_queue.started_job_registry)
            },
            "high_priority": {
                "pending": len(high_priority_queue),
                "failed": len(high_priority_queue.failed_job_registry),
                "finished": len(high_priority_queue.finished_job_registry)
            },
            "low_priority": {
                "pending": len(low_priority_queue),
                "failed": len(low_priority_queue.failed_job_registry),
                "finished": len(low_priority_queue.finished_job_registry)
            },
            "redis_info": {
                "used_memory": redis_client.info()["used_memory_human"],
                "connected_clients": redis_client.info()["connected_clients"],
                "total_commands_processed": redis_client.info()["total_commands_processed"]
            }
        }
    except Exception as e:
        logger.error(f"Erro ao obter estat√≠sticas da fila: {e}")
        return {"error": str(e)}

def cancel_user_tasks(user_id: int) -> int:
    """Cancela todas as tarefas de um usu√°rio espec√≠fico"""
    canceled = 0
    try:
        # Cancelar jobs agendados
        scheduled_registry = shared.rq_queue.scheduled_job_registry
        for job_id in list(scheduled_registry.get_job_ids()):
            try:
                job = Job.fetch(job_id, connection=redis_client)
                if job.args and len(job.args) > 0 and job.args[0] == user_id:
                    job.cancel()
                    shared.rq_queue.remove(job_id)
                    canceled += 1
                    logger.debug(f"Job {job_id} cancelado para usu√°rio {user_id}")
            except (NoSuchJobError, AttributeError):
                continue
        # Cancelar jobs pendentes
        for job in shared.rq_queue.jobs:
            try:
                if job.args and len(job.args) > 0 and job.args[0] == user_id:
                    job.cancel()
                    canceled += 1
                    logger.debug(f"Job pendente cancelado para usu√°rio {user_id}")
            except Exception:
                continue
        if canceled > 0:
            logger.info(f"Cancelados {canceled} jobs para usu√°rio {user_id}")
        return canceled
    except Exception as e:
        logger.error(f"Erro ao cancelar jobs para usu√°rio {user_id}: {e}")
        return 0

# Executar limpeza peri√≥dica em thread separada
def periodic_cleanup_worker():
    """Worker para limpeza peri√≥dica executado em thread separada"""
    while True:
        try:
            # Limpeza de jobs
            cleanup_expired_jobs()
            # Limpeza de dados compartilhados
            shared.cleanup_expired_data()
            # Aguardar pr√≥xima execu√ß√£o (30 minutos)
            time.sleep(1800)
        except Exception as e:
            logger.error(f"Erro na limpeza peri√≥dica: {e}")
            time.sleep(60)  # Retry em 1 minuto

# Iniciar thread de limpeza
cleanup_thread = threading.Thread(target=periodic_cleanup_worker, daemon=True)
cleanup_thread.start()

logger.info("‚úÖ Sistema de tasks inicializado com otimiza√ß√µes para alta concorr√™ncia")
logger.info(f"üìä Configura√ß√µes: timeout={JOB_TIMEOUT}s, result_ttl={JOB_RESULT_TTL}s, max_retries={MAX_RETRIES}")

